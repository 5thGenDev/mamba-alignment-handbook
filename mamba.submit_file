####################
#
# Run this along with bash script to run conda env within docker image
#
####################

# Job Universe. Standard, vanilla or docker.
universe         = docker
docker_image     = nvcr.io/nvidia/pytorch:24.01-py3

# Executable and its arguments 
executable    = mamba.sh
arguments     = 

# No need to mount if running on /mnt/

# Input, Output and Log files
log    = /vol/research/diffusionModels_NAS/c$(cluster).p$(process).log
output = /vol/research/diffusionModels_NAS/c$(cluster).p$(process).out
error  = /vol/research/diffusionModels_NAS/c$(cluster).p$(process).error

# What to do with files.
should_transfer_files = YES
transfer_executable = true

# GPU, Storage and CUDA Requirements for the Job 
requirements = (CUDAGlobalMemoryMb > 70000) && (HasWeka) && (CUDACapability > 7.6) && NotProjectOwned

# This job will complete in less than 1 hour (pp to 72 hours) and This job can checkpoint
+JobRunTime = 1
+CanCheckpoint = true

# Request for guaranteed run time(measured in s to match epoch runtime). 0 mean job is happy to checkpoint and move at any time.
# This lets Condor remove our job ASAP if a machine needs rebooting. Useful when we can checkpoint and restore
MaxJobRetirementTime = 0

# Resource requirements. Needs to be specified for the AI@Surrey cluster if requesting a GPU
request_CPUs   = 2
request_memory = 10000
# Standard RAM on machine (directly decide OOM error or not).

# Run job
queue 1

