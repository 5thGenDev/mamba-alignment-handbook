####################
#
# Run this along with bash script to run Python env within docker image
#
####################

# Job Universe. Standard, vanilla or docker.
universe         = docker
docker_image     = nvcr.io/nvidia/pytorch:23.12-py3

# Executable and its arguments 
executable    = sft.sh
arguments     = 

# No need to mount if running on /mnt/

# Input, Output and Log files
log    = /vol/research/diffusionModels_NAS/c$(cluster).p$(process).log
output = /vol/research/diffusionModels_NAS/c$(cluster).p$(process).out
error  = /vol/research/diffusionModels_NAS/c$(cluster).p$(process).error

# What to do with files.
should_transfer_files = YES
transfer_executable = true
transfer_output_files = /vol/research/diffusionModels_NAS/c$(cluster).p$(process).checkpoint

# GPU, Storage and CUDA Requirements for the Job 
requirements = (CUDAGlobalMemoryMb > 70000) && (CUDACapability > 7.6) && (HasWeka) && (HasDocker)

# This job will complete in less than 1 hour. Up to 72 hours. 
#This job can checkpoint
+JobRunTime = 9
+CanCheckpoint = true

# Request for guaranteed run time(measured in s to match epoch runtime). 0 mean job is happy to checkpoint and move at any time.
# This lets Condor remove our job ASAP if a machine needs rebooting. Useful when we can checkpoint and restore
MaxJobRetirementTime = 0

# Resource requirements
request_GPUs 	= 2
+GPUMem 	= 80000 
request_CPUs   = 10
request_memory = 20000
# Standard RAM on machine (directly decide OOM error or not).

# Run job
queue 1
